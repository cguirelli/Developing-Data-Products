rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
closeAllConnections()
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
trainIndex
-trainIndex
testing = adData[-trainIndex,]
closeAllConnections()
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
trainIndex
-trainIndex
View(adData)
closeAllConnections()
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
# # opção a
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
View(testing)
View(training)
closeAllConnections()
rm(list=ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(mixtures)
?hist
View(concrete)
hist(concrete$Superplasticizer)
View(testing)
hist(training$Superplasticizer)
hist(testing$Superplasticizer)
hist(training$Superplasticizer)
hist(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer))
hist(log(training$Superplasticizer))
min(concrete$Superplasticizer)
max(concrete$Superplasticizer)
log(1)
log(0)
hist(concrete$Superplasticizer)
hist(log(SuperPlasticizer + 1))
hist(log(concrete$SuperPlasticizer + 1))
log(concrete$SuperPlasticizer + 1)
concrete$SuperPlasticizer + 1
concrete$Superplasticizer+1
log(concrete$Superplasticizer+1)
hist(log(concrete$Superplasticizer+1))
hist(log(concrete$Superplasticizer))
hist(log(concrete$Superplasticizer+1))
closeAllConnections()
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
?preProcess
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
closeAllConnections()
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
closeAllConnections()
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
closeAllConnections()
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
install.packages("dplyr")
closeAllConnections()
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
# compute the model with non_pca predictors
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
install.packages("e1071")
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
# compute the model with non_pca predictors
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
closeAllConnections()
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
suppressMessages(library(dplyr))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
suppressMessages(library(dplyr))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
names(new_testing)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
# perform PCA extraction on the new training and testing sets
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
# perform PCA extraction on the new training and testing sets
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
# perform PCA extraction on the new training and testing sets
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_resul
closeAllConnections()
rm(list=ls())
install.packages(c("data.table", "evaluate", "formatR", "highr", "Rcpp"))
install.packages("dplyr")
install.packages("AppliedPredictiveModeling")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
install.packages("RcppEigen")
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
utils:::menuInstallPkgs()
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
utils:::menuInstallPkgs()
update.packages(ask='graphics',checkBuilt=TRUE)
install(caret)
install.packages("ggplot2")
install.packages("caret")
chooseCRANmirror()
setRepositories()
install.packages("ggplot2")
install.packages("caret")
utils:::menuInstallPkgs()
update.packages(ask='graphics',checkBuilt=TRUE)
update.packages(ask='graphics',checkBuilt=TRUE)
update.packages(ask='graphics',checkBuilt=TRUE)
q()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("caret")
library(caret)
sessionInfo()
packageVersion("brglm")
install.packages("C:/Users/Cleber/Downloads/brglm_0.5-9.tar.gz", repos = NULL, type = "source")
packageVersion("brglm")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(caret)
packageVersion("caret")
install.packages("MatrixModels")
library(caret)
install.packages("caret")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(ggplot2)
library(rattle)
library(caret)
install.packages("rattle")
library(rattle)
library(rattle)
library(ggplot2)
library(caret)
install.packages("brglm")
library(brglm)
?remove.packages
remove.packages("brglm")
install.packages("brglm")
packageVersion("brglm")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(rpart)
library(ggplot2)
library(rattle)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
model<-train(Class ~ .,data = training, method = "rpart")
closeAllConnections()
rm(list=ls())
closeAllConnections()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(rpart)
library(ggplot2)
library(rattle)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,data = training, method = "rpart")
fancyRpartPlot(model$finalModel)
)
library(rpart)
model<-train(Class ~ .,data = training, method = "rpart")
fancyRpartPlot(model$finalModel)
library(rattle)
fancyRpartPlot(model$finalModel)
install.packages("RGtk2")
closeAllConnections()
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(rpart)
library(ggplot2)
library(rattle)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(rpart)
library(ggplot2)
library(rattle)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,data = training, method = "rpart")
fancyRpartPlot(model$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model$finalModel)
closeAllConnections()
rm(list=ls())
library(pgmm)
data(olive)
olive = olive[,-1]
model<-train(Area ~ .,data = olive, method = "rpart")
library(caret)
library(pgmm)
library(ggplot2)
library(caret)
data(olive)
olive = olive[,-1]
model<-train(Area ~ .,data = olive, method = "rpart")
library(rpart)
model<-train(Area ~ .,data = olive, method = "rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
fancyRpartPlot(model$finalModel)
library(caret)
library(rattle)
fancyRpartPlot(model$finalModel)
print(model$finalModel)
View(newdata)
View(olive)
closeAllConnections()
rm(list=ls())
library(pgmm)
library(ggplot2)
library(caret)
library(rpart)
library(rattle)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(1234)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,
data=trainSA,
method="glm",
family="binomial")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
closeAllConnections()
rm(list=ls())
library(pgmm)
library(ggplot2)
library(caret)
library(rpart)
library(rattle)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
model <- train(y ~ ., data=vowel.train, method="rf")
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
model <- train(y ~ ., data=vowel.train, method="rf")
varImp(model)
closeAllConnections()
rm(list=ls())
library(pgmm)
library(ggplot2)
library(caret)
library(rpart)
library(rattle)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
model <- train(y ~ ., data=vowel.train, method="rf")
varImp(model)
closeAllConnections()
rm(list=ls())
library(pgmm)
library(ggplot2)
library(caret)
library(rpart)
library(rattle)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,
data=trainSA,
method="glm",
family="binomial")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
closeAllConnections()
rm(list=ls())
library(pgmm)
library(ggplot2)
library(caret)
library(rpart)
library(rattle)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
model <- train(y ~ ., data=vowel.train, method="rf")
varImp(model)
install.packages("shiny")
install.packages(c("RcppArmadillo", "rpart.plot"))
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
x=c(1,2,3)
x
dim(X)
dim(x)
size(x)
lenght(x)
length(x)
tail(x)
tail(x,1)
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
shiny::runApp('D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto')
library(slidify)
library(slidifyLibraries)
library(RCurl)
setwd("D:/CLEBER/Pessoal/Diversos/Estudo Online/Data Science Specialization/Developing Data Products/projeto/DDP_project_Slidify")
slidify('index.html')
publish(title = 'DDP project v1', 'index.html', host = 'rpubs')
install packages("markdown")
install_packages("markdown")
install.packages("markdown")
install.packages("markdown")
install.packages("markdown")
install.packages("markdown")
install.packages("markdown")
install.packages("markdown")
install.packages("markdown")
install.packages("markdown")
library(markdown)
rpubsUpload('DDP project v1', 'index.html', id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
